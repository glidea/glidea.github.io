{"posts":[{"title":"并发基础","content":"创建线程 创建继承 Thread 类的实例 创建实现 Runnable 接口的实例，注入 Thread 类，或者丢给线程池处理（线程池内部自动创建线程，并启动） 创建实现 Callable 接口的实例，注入 FutureTask 类，此时这就变成了一个 Runnable 实例，创建线程的方式跟第二点一样 创建实现 Callable 接口的实例，直接丢给线程池的Future submit(Callable task)执行 第三种方式只是在第二种方式上做的拓展，使其具有直接返回线程执行结果的能力，原理是一样的 第四种则完全和第三种一样，在submit()内部，一样会把 Callable 实例变成 Runnable 实例 这样看来本质上只有两种方法创建线程，Oracle 官方文档也写两种 不过认为只有一种，个人觉得也是一种可行的说法，因为这些方法都可以归纳为创建了 Thread 实例 实现 Runnable 接口的优势 实现了 具体任务 和 线程环境 的解耦 基于上一点可以很好的实现线程的复用。比如线程池每个线程的run()都不断从 WorkQueue 中获取 Runnable 实例，并执行 Runnable 实例的run()（注意前后两个run()的区别） 此外由于单继承机制，实现 Runnable 接口的实现类有更好的拓展性 启动线程 调用start()启动线程，而非run()。run 方法只是一个普通方法，而 start 方法会创建线程环境，并调用 run 方法执行 停止线程 外部调用 interrupt() 向线程发送中断信号 线程通过isIntercepted()轮询到中断信号后，开始善后工作 当线程处于阻塞状态时，接收到中断信号，一般会被自动唤醒，并抛出InterruptedException。同时其中断标志被重置，需要在catch内重新发送中断信号，外部的轮询才能感知到 但线程也可能不会被唤醒，最直观的原因就是：线程不去捕获InterruptedException（这取决于以何种方式进入这些状态）。如线程在等待synchronize锁（BLOCKED），或在使用不可打断方式等待Lock锁（WAITING），都无法响应中断 所有强制停止线程，不留给线程善后的余地的方式都是不推荐的（stop()、suspend()） 线程状态 NEW：Thread state for a thread which has not yet started BLOCKED：Thread state for a thread blocked waiting for a monitor lock. A thread in the blocked state is waiting for a monitor lock to enter a synchronized block/method or reenter a synchronized block/method after calling Object.wait WAITING：A thread in the waiting state is waiting for another thread to perform a particular action. For example, a thread that has called Object.wait() on an object is waiting for another thread to call Object.notify() or Object.notifyAll() on that object. A thread that has called Thread.join() is waiting for a specified thread to terminate TIMED_WAITING：Thread state for a waiting thread with a specified waiting time TERMINATED：Thread state for a terminated thread. The thread has completed execution. 思考题 线程相关的方法？ 线程的属性？ 多线程在带来 CPU 高利用率的同时，也带来了哪些问题？ 多线程和高并发什么关系？ ","link":"https://glidea.github.io/post/pTSnvmBJR/"},{"title":"类加载","content":"类加载（装载）的过程 加载：找到并加载类的二进制流至方法区，并在堆中创建 Class 对象代理，以对方法区对应数据的访问（此阶段由类加载器完成） 链接 验证：校验类是否符合虚拟机的约束 准备：为静态变量分配空间并设置默认值，为所有常量分配空间并赋值（对于引用变量或常量只是预设了引用本身） 解析：将类或接口，字段，方法的符号引用（java/lang/Object） -&gt; 直接引用（内存中的地址） 初始化：把 static变量、static引用常量的赋值动作、static代码块合并成 &lt;cinit&gt;() 方法，并执行。主要是为了完成赋值 类加载步骤只是按顺序开始，并非按顺序结束，也就是说不同阶段可能交叉执行。 但解析不一定按顺序执行，可能在初始化后执行 类初始化的时机 首次被 new 了（或者反射，反序列化） 子类要初始化，父类要是还没初始化，就会引发 静态变量，静态方法，引用类型的静态常量首次被调用 main 方法所在的类，第一时间就被初始化 通过子类访问父类的静态变量，只会导致父类初始化 但子类已经被加载，只是还没初始化 如果 A 类调用了 B 类的基本类型的静态常量 C，B类不会被初始化 因为基本类型的静态常量的内容是不变的，所以 C 已经直接被放到了 A 类的常量池中 类加载器 名称 加载哪的类 说明 Bootstrap ClassLoader JAVA_HOME/jre/lib C语言编写，无法直接访问 Extension ClassLoader JAVA_HOME/jre/lib/ext 双亲是 Bootstrap Application ClassLoader classpath 双亲是 Extension 自定义加载器 自定义 双亲是 Application ClassLoader 之间的协作关系是双亲委派机制 SPI 机制实现了上层加载器对下层加载器的委托 ","link":"https://glidea.github.io/post/6vzHvO2bs/"},{"title":"事务","content":"事务的特性 原子性：事务是由一组SQL组成的逻辑处理单元，要么一起成功，要么一起失败。有undo log(逻辑日志)保证 持久性：事务一旦提交，最终一定会持久化到硬盘（数据先写到内存），不会因为宕机而丢失。有redo log(InnoDB)保证 隔离性：保证事务执行时尽可能不受其它事务的影响，事务的隔离分为不同级别 一致性：事务执行后的到的是正确的数据状态，完整性约束不被破坏（数据库的各种约束，以及业务完整性），是事务所要追求的目标，是基于其它三点的 事务并发产生的问题 脏读：读到别的事务未提交的数据 不可重复读：多次查询同一记录得到不同的结果，或记录凭空消失（读取到别的事务已提交的修改或删除的结果） 幻读：多次查询某一范围的记录，会凭空出现一些记录（读取到别的事务已提交的插入结果） 上述问题主要是一个事务的写对另一个事务的读产生的影响 除此之外还有多个事务对同一资源写操作的并发安全问题，此问题通过锁机制解决，与隔离级别无关 解决并发读的隔离级别 快照读模式下，通过MVCC实现；当前读模式下，通过锁实现 读未提交：啥隔离措施都没有 读已提交：解决脏读，一个事务读取数据时总是读取最近一次被commit的版本 快照读：当前事务的视图在每次select时读取的都是最近commit的版本 当前读：使用锁（个人觉得也解决了不可重复读，若加的是表锁，连幻读都莫得） 可重复读：解决脏读，不可重复读，部分幻读问题。一个事务读取数据时总是读取当前事务第一次查询出的版本（注意是第一次，而不是事务开始时） 快照读：当前事务的视图只读取第一次select的版本 当前读：使用行锁加间隙锁（或表锁），即next-key lock 串行化：解决幻读 隔离级别越高，隔离性越强，一致性也因此更好，但是性能就越差 MVCC解决不了的幻读是插入产生主键重复现象，而当前事务查询出该主键并没有被占用 当前读不会有这种问题 解决并发更新的锁机制 MySQL的锁只有悲观锁，分为读锁和写锁，每种锁又可以细分为行锁和表锁 并发锁队列，读锁不阻塞后头的锁，写锁会阻塞后头。据此可推导出锁的读写规则 执行更新SQL，自动为当前事务拿写锁；执行查询SQL，不会加任何锁，但可以通过for update或lock in share mode 手动加写锁或读锁（用于在应用层实现大粒度的悲观锁） InnoDB中SQL如果用上了索引，加行锁，反之拿表锁 思考题 哪行锁和表锁的区别是什么？ 如何解决因使用行锁导致的死锁？ ​ 顺序加锁，设置合适的锁超时时间，开死锁检测，尽量晚加锁，金额拆行累加（参考LongAdder） 行锁的间隙锁？ MVCC的细节？ ","link":"https://glidea.github.io/post/h1icQUmLi/"},{"title":"垃圾回收","content":"对象间的四种引用 强引用：只要 GC Roots 强引用的到，就不会被 GC 回收 软引用：某次 GC 后内存还不够，就把只有软引用的 obj 列入再次 GC 的回收范围 弱引用：如果只有软引用，一旦 GC，就会被回收 虚引用：和弱引用一样不会对 obj 的生存时间造成影响，与弱引用不同的地方在于，其使用的时必须要配合引用队列使用 软弱引用可以关联引用队列，obj 回收后软弱引用对象会自动加入引用队列，便于回收软弱引用对象 虚引用关联了默认的引用队列 软弱引用可以用于缓存的实现 虚引用对象在其引用的 obj 被回收的时候，会自动加入引用队列等待扫描线程，从而起到通知系统 obj 被回收的作用。你可能会对这个作用感到疑惑，系统自个回收的，系统会不知道？原因在于虚引用指向的是特殊的 obj，而系统回收 obj 时，从来都是“杀人不睁眼的”，又因为特殊的 obj 的“特殊”是指其在死后还需要处理一些善后工作，所以必需要有这么一个通知机制。 虚引用具体用途是用于堆外内存的管理，拿 NIO 举例子，当 Buffer 对象被回收后，虚引用通知系统释放 Buffer 对象指向的本地内存 判断对象是否可达 沿着 GC Roots 的强引用链搜索，找不到的都是不可达对象 可以作为 GC Roots 的对象 虚拟机栈中所有栈帧使用到的对象，譬如各个线程的栈使用到的局部变量，方法参数等 被拿来当锁的对象 方法区中类静态属性引用的对象，譬如引用类型的静态变量 Native 方法引用的 Java 对象 异常对象，类加载器，基本类型的 Class 对象 ...... 判断对象是否可以回收 先判断是否可达，不可达的对象还要在看看有没有软引用。 若有软引用，则先不着急回收该对象，在进行一次 GC 后，若空间还不足，再回收 回收算法 标记复制 O(k) 标记存活对象，然后将其复制到另一块内存 优点：快，只需要标记 + 复制 缺点：浪费空间 用途：回收存活率低的新生代 标记清除 O(n) 标记存活对象，然后扫描整个空间，统一回收未被标记的对象 优点：作为老年代回收算法，延迟低 缺点：有内存碎片，吞吐量不行 用途：用于注重延迟的老年代收集器 标记整理 O(n) 标记存活对象，然后扫描整个空间，同时把标记对象往前挪 优点：作为老年代回收算法，吞吐量高 缺点：需要移动对象，并更改引用。速度慢，延迟高 用途：用于注重吞吐量的老年代收集器 标记清除和标记整理结合使用。如 CMS 平时使用标记清除，碎片过多时，采用标记整理 垃圾收集器 Serial / Serial Old 比其他收集器的单线程快 是客户端模式的默认组合（串行） Parallel Scavenge / Parallel Old 注重吞吐量的收集组合，也是 1.8 默认组合 -XX:MaxGCPauseMillis：保证每次 GC 不会超过这个时间，调低会降低新生代空间，增加回收垃圾所需的总时间，从而导致吞吐量下降（控制延迟常数） -XX:GCTimeRatio：设置 GC 时间可占用总时间的最大比率（控制延迟比例） -XX:+UseAdaotiveSizePolicy：让收集器自调节性能参数 ParNew：多线程版本的 Serial CMS 最佳的新生代可用收集器 JDK9 后 ParNew 并入 CMS，但至此 G1 替代 ParNew + CMS 成为首选方案 CMS：响应优先 运作过程 初始标记：标记 GC Roots 能直接关联的对象（耗时很短，只开了单线程） 并发标记：在初始标记的基础上继续标记 重新标记：修正标记，处理在并发标记的时候，先被标记为垃圾，后面重新被引用的情况 并发清除：清理垃圾对象，不需要移动存活对象（并发过程的新对象，默认存活） 缺点 并发期间开启的回收线程数量是 (核心数 + 3) / 4，在核少的服务器上，会挤占过多的 CPU 资源 由于无法处理浮动垃圾，清理前需要预留部分空间，即老年代占用达到预设百分比后就触发 CMS（Old GC），而不是像别的收集器等到快满的时候才收集 如果预留空间无法容纳浮动垃圾（并发失败），则启用 Serial Old，最新版本采用了 Parallel Old 做备胎 由于使用标记 - 清除，当内存碎片太多时，启用 Full GC （为啥不只是 Old GC） 增量更新有 bug，所以在 remark 阶段会重新扫描（那并发标记阶段不是毫无意义了吗，CMS 不是卵用没有？） G1 思考题 怎么解决并发标记时产生的标记错误 卡表什么作用，怎么实现 YGC 在标记过程的剪枝 写屏障和卡表更新的关系 OopMap 与安全区域的关系 ","link":"https://glidea.github.io/post/kRaswf51Z/"},{"title":"内存结构","content":"虚拟机栈和本地方法栈 栈帧的组成 局部变量表：存放方法参数、局部变量 表item可复用（注意对gc的影响） 这玩意是创建时从运行时常量池弄过来的 操作数栈：类似于数据寄存器，存储临时计算结果 动态连接：当前方法所在类在运行时常量池中的引用 The reference points to the constant pool for the class of the method being executed for that frame 方法返回值和返回地址 异常处理表 栈上分配 开启逃逸分析和标量替换后，非逃逸对象可以在栈上分配，但大对象还需要在堆上分配 栈上分配将极大提高性能，因为栈空间连续，方便利用CPU缓存 异常情况 StackOverflow：栈帧太多 OOM：内存不足，无法申请新的栈帧 HotSpot 的实现 实际上VM Stack和Native Stack并非要实现两个栈，HotSpot 是把两个合并成Mixed Stack 而 Java 线程与 Native 线程是一一对应的，Mixed Stack本身就可以认为是一个操作系统调用栈 程序计数器 作用：记住线程下一条 “JVM指令” 的地址（指令在方法区中） 是实现分支、循环、跳转、异常处理的基础设施 以及保存上下文切换的执行进度 补充 JVM的计数器是软件方法实现的，并非物理上的计数器（寄存器） 执行native方法的时候，JVM计数器的值为undefined，物理PC存储的是CPU指令行号，JVM PC存储的是JVM指令行号 唯一不存在OOM的区域 堆 年轻代与老年代 G1 不再完全基于传统分代模型，而是采用基于 Region 的动态分代策略 ZGC 目前不分代，ZGC 分代实现仍在探索中 StringTable 入池原理 字符串变量拼接原理是StringBuilder //需主动入池 字符串常量拼接原理是编译期优化 //被动入池 被动入池：懒加载 主动入池：str.intern() 1.6中，若StringTable中有str.value，则不放入；若没有，则放入str的副本 1.7以后，直接放入str本体（可能和StringTable从元空间剥离，逻辑上放在了堆上有关） 调优 因为StringTable是哈希表结构，所以可以通过调节桶数量进行调优，桶数量通过虚拟机参数调节 思考题 对象从创建到被回收的过程是怎样的？ 什么是空间担保？ 方法区 The Java Virtual Machine has a method area that is shared among all Java Virtual Machine threads. The method area is analogous to the storage area for compiled code of a conventional language or analogous to the &quot;text&quot; segment in an operating system process. It stores per-class structures such as the run-time constant pool, field and method data, and the code for methods and constructors, including the special methods used in class and instance initialization and interface initialization. 组成 类信息：包含类的字段，方法，特殊方法。但注意 Class 对象在堆中 运行时常量池：就是一张数组结构的表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、对象地址等信息 逻辑包含字符串常量池，1.7后StringTable继续待在堆中，方法区别的玩意放到了本地内存的元空间 直接内存 性能好，直接分配在Native堆，减少了Java堆和Native堆之间的copy 参考 https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html https://blog.jamesdbloom.com/JVMInternals.html ","link":"https://glidea.github.io/post/vwp0rgIpw/"},{"title":"操作系统 - 内存管理","content":"一、程序被装入内存运行前所执行的过程 编译：代码文件 -&gt; 目标模块（高级语言 -&gt; 机器语言） 链接：目标模块 -&gt; 装入模块，此时形成了完整的逻辑地址 静态链接：全部无脑拼凑 装入时动态链接：等到放入内存时，再进行拼凑 运行时动态链接：等到放入内存，并需要时，再进行拼凑 装入：装入模块放入内存，并转换地址 绝对装入：编译时产生绝对地址（程序的内存地址固定，仅适用于单道程序环境） 可重定位装入（静态重定位）：装入时根据 程序基地址 + 逻辑地址 -&gt; 绝对地址（适用于早期多道批处理阶段） 动态运行时装入（动态重定位）：运行时根据 重定位寄存器中的程序地址 + 逻辑地址 -&gt; 绝对地址 二、操作系统管理内存哪些方面 内存空间分配与回收 连续分配：分配给进程的是一个连续的内存空间 单一连续分配（仅支持单道程序） 固定分区分配：内存用户空间分为若干个固定大小的分区，每个分区只能装一道作业 缺：缺乏灵活性，内部碎片多 动态分区分配：在进程装入内存时，根据进程的大小动态地建立分区 动态分区的各内存分区大小不一致，使用情况也不一致，需要空闲分区表或链存储结构信息 当多个空闲分区满足进程的需求的时候，要怎么选择分区？ 首次适应 地址递增排序，从头到尾，找到装得下的就用 优：性能好，可以保留高地址大分区 缺：低地址会产生较多碎片 最佳适应 空间递增排序，从头到尾，找到装得下的就用 优：保留大分区 缺：性能差，完事需要重新排列 最坏适应 空间递减排序，从头到尾，找到装得下的就用 优：减少外部碎片 缺：性能差，完事需要重新排列 邻近适应（循环首次适应算法）（数据结构：空闲分区循环链表） 地址递增排序，从上次查找结束的位置开始，找到装得下的就用 优：性能最好 缺：导致大分区稀缺 缺：外部碎片多，虽然可以用紧凑技术解决，但是代价太高 非连续分配：分配给进程的可以是多个零散的内存空间 基本分页存储管理：进程分页装进固定分区的内存 地址转换：根据逻辑地址算出页号，偏移量 - 》根据PTR中的页表长度判断页号是否越界 - 》如果没越界，根据PTR的页表始址，页表项长度，页号算出该页号对应的地址，得到内存块号 - 》根据块号，页面大小，偏移量算出物理地址 优：内存利用率高，只有少量页内碎片 缺：不方便按照逻辑模块实现保护和共享 PTR中的数据是进程被调度的时候由PCB整进来的 上述地址转换过程引入快表机制，将最近用过的页表项放入快表（类似于缓存），由于快表在寄存器中，速度比内存快，所以能提高速度 由于一个页表的页表项必须连续存储，所以页表需要很大的连续空间，而且一段时间内，很多页表项都用不到，没必要常驻内存，所以可以拆分成多个页表，再搞个页目录表管理多个页表 基本分段存储管理：进程分段装进不分区的内存（不定长，不分区的分页管理） 地址装换：和分页存储不同的是，需要根据 段表记录的段长 判断 段内地址是否越界 优：容易实现共享和保护 缺：段太大的话，又和连续分配一样容易产生外部碎片了 段页式存储管理：进程分段，段内再分页装进固定分区的内存 内存空间的扩充（基于局部性原理） 覆盖技术：将程序分成多个模块，热点模块装入一个固定区，其它模块根据需要换出换入某个覆盖区（调度单位：进程模块） 缺：程序覆盖结构必须由程序员指定，编程难度大，这种技术已成为历史 交换技术：内存紧张时，将挂起状态的进程换出到外存对换区，再换入文件区的某些进程（调度单位：进程） 缺：调度粒度大 虚拟内存：利用覆盖技术、交换技术动态换入换出页（覆盖和交换的调度单位：页或段） 特征：多次性（装入）、对换性（换出换入）、虚拟性 前提：操作系统提供请求分页、或分段、或段页式存储管理功能 运作机制：访问信息不再内存，通过请求调页功能，将信息换入到内存；内存不够用时，通过页面置换功能，将用不到的信息换出到外存 地址转换（如果使用绝对装入的方式，不需要操作系统干这活，当然这样连操作系统都不需要了，因为绝对装入只适用于单道程序环境） 存储保护 ","link":"https://glidea.github.io/post/qxM2zyb0K/"},{"title":"操作系统 - 同步","content":"一、进程互斥 实现进程互斥的代码分为 进入区 临界区 退出区 剩余区 进程互斥遵循的原则 空闲让进 忙则等待 有限等待 让权等待：进不了临界区的进程要先放弃处理机，不要干等 进程互斥的软件实现方法 单标志法：傻屌算法 双标志先检查法： 双标志后检查法 Peterson算法（孔融让梨法） 进程互斥的硬件实现方法 中断屏蔽法 原理：开关中断 优：简单高效 缺：只适用于单核环境和内核进程 TS和Swap指令 原理：将检查和上锁变为原子操作 优：简单，适用于多处理机 缺：不满足“让权等待” 二、进程互斥和进程同步的关系 互斥是特殊的同步，是进程访问资源的次序上的同步 同步大多情况下基于互斥 三、信号量机制：实现进程互斥和进程同步的终极底层方案 实现进程互斥 设置互斥信号量 = 1、2...（资源数量） 临界区之前执行P操作（lock） 临界区之后执行V操作（unlock） 实现进程同步 设置同步信号量 = 0 在“前操作”之后执行V操作（notify） 在“后操作”之前执行P操作（wait） 四、经典进程同步和进程互斥问题 生产者 - 消费者问题（lock不能在wait前面） 多生产者 - 多消费者问题 吸烟者问题（单生产者 - 多消费者问题） 读者 - 写者问题（复杂互斥问题） 哲学家进餐问题（一个进程需要同时持有多个临界资源） 五、死锁 定义：各个进程互相等待对方手里的资源，导致各个进程都阻塞，无法向前推进 死锁产生的必要条件 互斥条件：争抢互斥非共享的资源才会导致死锁 不剥夺条件：进程保持的资源只能主动释放，不可强行剥夺 请求和保持条件：请求别的资源，同时可以保持某些资源不放 循环等待条件：存在一种进程资源的循环等待链 在具备必要条件后，只有对不可剥夺资源的不合理分配才会导致死锁（实际上有五个条件） 死锁的处理策略 预防：破坏产生死锁的必要条件 避免：避免系统进入不安全的状态 银行家算法 死锁的检测和解除：允许死锁的发生，死锁负责检测出死锁并解除 检测：资源分配图是否可简化到无边可消 解除：资源剥夺法、撤销进程法、进程回退法 ","link":"https://glidea.github.io/post/VuofrILmn/"},{"title":"操作系统 - 调度机制","content":"一、处理机调度的三个层次 作业调度（高）：从后备队列中选择合适的作业将其从外存调入内存，并为其创建进程 内存调度（中）：从挂起队列中选择合适的进程将其数据从外存调回内存（内存不足时，某些进程会被挂起到外存） 进程调度（低）：从就绪队列中选择一个进程为其分配处理机**（内存 --》CPU）** 二、进程调度 什么时候需要调度进程 运行中的进程主动放弃处理机资源 进程正常终止，或发生异常终止 主动阻塞（如 等待I / O） 运行中的进程被动放弃处理机资源 分配的时间片用完 有更高优先级的进程进入就绪队列，或者操作系统有更紧急的事要CPU处理（如 I / O中断） 什么时候一定不能进行进程调度 处理中断的时候 进程在操作系统内核程序临界区中（进程运行到锁里的代码，这时要让进程尽快执行完） 原子操作过程中 进程调度和进程切换 狭义进程调度：从就绪队列选择一个要运行的进程 进程切换：保存原来进程的运行环境，恢复新进程的运行环境 广义进程调度：狭义进程调度 + 进程切换 三、调度算法的评价指标 CPU利用率：忙碌时间 / 总时间 系统吞吐量：完成作业数 / 总时间 （作业完成效率） 周转时间 周转时间：作业完成时间 - 作业提交时间 （等待 + 运行） 平均周转时间：各作业周转时间之和 / 作业数 带权周转时间：作业周转时间 / 作业运行时间 （越小越好）（衡量作业受CPU宠幸的程度） 平均带权周转时间：各作业带权周转时间之和 / 作业数 等待时间 响应时间：从用户提交请求到首次产生响应的时间 四、调度算法 先来先服务（FCFS）：只考虑进程的等待时间 规则：按照作业 / 进程到达的先后顺序进行服务 是否可抢占：NO 优：公平 缺：短作业 / 进程不爽，自己就是撒泡尿，还要等个拉屎的 短作业优先（SJF）：只考虑进程的运行时间（无法真正实现） 规则：先服务要求服务时间最短的作业 / 进程 是否可抢占：NO or YES 优：“最短的” 平均等待时间 缺：长作业 / 进程不爽，自己就是拉个屎，撒尿的抢着来 补充：SJF的抢占式版本SRNT算法：只考虑剩余运行时间，优点和缺点都更极端 高响应比优先（HRRN）：考虑了进程的等待和运行时间 规则：响应比高的作业 / 进程优先，响应比 =（等待时间+运行时间）/ 运行时间 是否可抢占：NO 优：综合了上述两种算法的优点 时间片轮转（RR）：分时、进程专属版FCFS！ 规则：大家轮流上3秒厕所 是否可抢占：YES，和涉及到时间片的算法都是抢占式的，屎拉到一半都得夹断出来 优：公平，适用于分时系统 缺：资源开销大，不能处理紧急任务 补充：时间片太大，退化成FCFS；时间片太小，开销太大 优先级调度（有抢占式和非抢占式的） 规则：优先调度优先级最高的作业 / 进程 是否可抢占：NO or YES 优：可处理紧急任务，适用于实时系统 多级反馈队列：进程专属的完美算法 规则 设置多级就绪队列，各级队列优先级从高到低，时间片从小到大（RR和优先级调度的结合算法） 新进程到达时先进入第1级队列，按FCFS原则排队等待被分配时间片，若用完时间片进程还未结束，则进程进入下一级队列队尾（如果此时已经是在最下级的队列，则重新放回该队列队尾） 只有第k级队列为空时，才会为k+1级队头的进程分配时间片 是否可抢占：YES 优点 对各类型进程相对公平（FCFS的优点） 每个新到达的进程都可以很快就得到响应（RR的优点） 短进程只用较少的时间就可完成（SPF的优点） 不必实现估计进程的运行时间（避免用户作假） 可灵活地调整对各类进程的偏好程度，比如CPU密集型进程、I / 0密集型进程（拓展：可以将因I / 0而阻塞的进程重新放回原队列，这样I / 0型进程就可以保持较高优先级） ","link":"https://glidea.github.io/post/4tq--pmpL/"},{"title":"操作系统 - 进程","content":"一、进程和程序有什么区别 程序是静态的，是存储在硬盘的可执行文件，是一系列指令的集合 进程是动态的，是存储在内存中的实体，是程序的一次执行过程 二、进程的组成 PCB：存放操作系统管理进程所需的信息（进程描述信息、进程控制管理信息、资源分配清单、处理机相关信息） PCB是进程存在的唯一标志 程序段：程序代码（指令集合） 数据段：运行过程中所产生的数据（代码中定义的变量） 三、进程的特征 动态性（基本特征） 独立性（资源调度的基本单位） 并发性 异步性 结构性 四、进程的组织方式 链接方式：按照进程状态将PCB分为多个队列 索引方式：按照进程状态将PCB分为多个索引表 五、进程的状态与转换 状态：创建、就绪、运行、阻塞、终止 基本状态之间的转换（原语实现转换的过程） 就绪 --》运行：进程被调度 运行 --》就绪：时间片用完，或CPU被高优先级进程抢占 运行 --》阻塞：进程用系统调用的方式，申请系统资源，或者请求等待某个事情的发生（比如其它进程的执行结果） 阻塞 --》就绪：资源已经分配，或者等待的事情发生（被动） 六、原语实现进程状态转换要干的事情 更新PCB的信息 所有进程控制原语一定会修改进程状态标记 剥夺当前运行进程的CPU使用权，要先保存运行环境，相反进程开始运行前，要恢复运行环境 将PCB插入合适的队列 分配 / 回收资源 七、进程通信的方式 共享存储：互斥访问一块共享空间 共享存储的实现可以基于存储区或者数据结构 管道通信：互斥访问一个共享文件（缓冲区） 一个管道只能实现半双工通信 写满时，不能再写，读空时，不能再读 没写满，不能读，没读空，不能写 消息传递：进程通过发送 / 接收原语来 发送 / 接收结构化的消息（消息头/消息体） 直接通信：消息直接挂到接收线程的消息队列里 间接通信：消息发送到公共信箱 八、线程和进程 多个线程从属于一个进程，线程是真正干事的，而进程是线程的容器 线程是处理机调度的单位，进程是资源分配的单位 同一进程内的线程切换不会导致进程的切换，运行环境也就无需改变，系统开销从而降低 九、线程的实现方式 应用通过线程库实现用户级线程并自主管理，操作系统不知道 将m个用户级线程映射到n个内核级线程（多对多模型） ","link":"https://glidea.github.io/post/dkeW2P5_b/"},{"title":"操作系统 - 基本概念","content":"一、操作系统的功能是什么 管理软硬资源：处理机、存储器、设备、文件的管理 向上层提供服务 向用户提供GUI，联机命令接口（单命令），脱机命令接口（批处理bat） 向应用程序提供程序接口（系统调用，广义指令） 对底层功能进行拓展 二、操作系统的特征是什么 并发（并行的超集）：一个时间段内，多件事情在宏观上同时发生，在微观上交替发生 共享（部分并发场景的条件） 互斥共享：一个资源，一个时间段内只允许一个进程访问 同时共享：一个资源，一个时间段内允许多个进程访问 虚拟 异步：在资源有限的情况下，并发环境下，进程的执行受到其它进程的制约，总是走走停停的 三、操作系统的特征之间的关系 并发和共享互为存在条件 没有共享，无法实现并发（可以实现非共享的并发） 没用并发，共享就没有意义 并发和共享是虚拟的前提条件 共享是并发的重要基础要素，而并发是虚拟性存在意义的前提 并发和共享必然导致异步 四、操作系统的发展背景和分类 手工操作阶段（手工输入一条条指令） 缺：人机速度矛盾（人工太tm慢了，机器等得很不耐烦） 批处理阶段 单道批处理系统（引入脱机输入输出技术） 优：缓解了人机速度矛盾 缺：内存中只有一道程序执行，资源利用率还是很低（每次只有一个进程走流程，没走到的部分只能干等着） 多道批处理系统（操作系统开始出现） 优：提高了资源利用率，多道程序可并发执行 缺：没有人机交互（给操作系统执行一堆命令，你只能选择等待或终止命令） 操作系统阶段 分时操作系统 优：提供人机交互 缺：不能优先处理紧急任务 实时操作系统（分软硬实时系统） 优：能优先处理紧急任务 两种系统的缺点在其应用领域都不算缺点 五、操作系统大内核的功能组成 时钟管理（分配时间片...） 中断处理（并发的前提：不必等到程序运行结束，才能切换程序） 原语（一种不可中断的程序，例如底层的CPU切换，进程通信...）（通过开关中断实现原子性） 对资源进行管理的功能（不直接涉及硬件的功能，微内核不包含） 进程管理 存储器管理 设备管理 六、运行态和中断机制 CPU的运行态 内核程序在核心态中执行特权指令和非特权指令（陷入指令除外） 应用程序在用户态中执行非特权指令 操作系统的中断机制 作用：中断当前运行的应用程序，CPU由用户态变成核心态，系统内核收回控制权 意义：中断是实现程序并发的前提 分类 内中断（异常）：与当前执行的指令有关，中断信号源自CPU内部 陷入，陷阱 故障 终止 外中断（狭义中断）：与当前执行的指令无关，中断信号源自CPU外部 时钟中断（当前程序的时间片用完的时候） I/O中断请求 执行原理 检查中断信号 内中断：CPU在执行指令时会检查异常 外中断：每个指令周期末尾，CPU会检查是否有外中断信号待处理 为中断信号找到相应的中断处理程序 根据中断信号类型，通过中断向量表，找到处理程序的指针 七、系统调用（一种特殊的异常） 系统调用与库函数的区别 有的库函数不包含系统调用 有的库函数是对系统调用的封装 什么功能要用系统调用实现 会直接影响其它进程的操作，比如涉及共享资源的有关操作 系统调用的过程 传递系统调用参数 用户态下发送系统调用请求：执行陷入指令（trap，访管指令），引起内中断，进入核心态 核心态下处理系统调用 返回应用程序，执行后续指令 ","link":"https://glidea.github.io/post/plMGqezrm/"}]}